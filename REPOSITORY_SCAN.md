# Repository Scan Report

**Date:** 2025-11-01
**Repository:** youtube.ai
**Status:** âœ… Complete Scan

---

## ğŸ“‹ Executive Summary

This repository contains a **dual-backend architecture** for a YouTube AI video processing platform:

- **NestJS Backend** (`nest-backend`): Primary API service handling uploads, transcoding, transcription, search, and user management
- **Python Backend** (`python-backend`): Specialized service for video summarization using OpenAI LLM

Both backends share:
- PostgreSQL database (with schema synchronization)
- Kafka event streaming (shared outbox pattern)
- Redis for caching/queuing
- AWS S3 for object storage

---

## ğŸ—ï¸ Architecture Overview

### System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Client Applications                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    NestJS Backend (Port 8080)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   REST API   â”‚  â”‚   Kafka      â”‚  â”‚   BullMQ Workers     â”‚  â”‚
â”‚  â”‚  Controllers â”‚  â”‚  Consumers   â”‚  â”‚   (Job Processors)   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚             â”‚             â”‚
        â–¼             â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL  â”‚ â”‚    Redis    â”‚ â”‚    Kafka     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Python Backend (Port 8081)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  FastAPI     â”‚  â”‚   Kafka      â”‚  â”‚   Celery Workers     â”‚  â”‚
â”‚  â”‚  Endpoints   â”‚  â”‚  Consumer    â”‚  â”‚   (Tasks)            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     External Services                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   AWS S3     â”‚  â”‚   OpenAI     â”‚  â”‚   OpenSearch        â”‚  â”‚
â”‚  â”‚   (MinIO)    â”‚  â”‚   API        â”‚  â”‚   (Elasticsearch)   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ NestJS Backend (`nest-backend`)

### Technology Stack

- **Framework:** NestJS 10.x (Node.js/TypeScript)
- **Database:** PostgreSQL with TypeORM
- **Cache/Queue:** Redis with BullMQ
- **Message Queue:** Kafka (Redpanda compatible)
- **Search:** OpenSearch (Elasticsearch compatible)
- **Object Storage:** AWS S3 (MinIO compatible)
- **Video Processing:** FFmpeg (via fluent-ffmpeg)
- **Authentication:** JWT with Passport

### Project Structure

```
nest-backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.ts                          # Application entry point
â”‚   â”œâ”€â”€ app.module.ts                     # Root module
â”‚   â”œâ”€â”€ app.controller.ts                 # Root controller
â”‚   â”œâ”€â”€ app.service.ts                    # Root service
â”‚   â”‚
â”‚   â”œâ”€â”€ common/                           # Shared utilities
â”‚   â”‚   â”œâ”€â”€ decorators/                   # Custom decorators (Public, etc.)
â”‚   â”‚   â”œâ”€â”€ dtos/                         # Common DTOs (pagination, etc.)
â”‚   â”‚   â”œâ”€â”€ enums/                        # Enums (config, entities, status)
â”‚   â”‚   â”œâ”€â”€ filters/                      # Exception filters
â”‚   â”‚   â”œâ”€â”€ guards/                       # Auth guards (JWT)
â”‚   â”‚   â”œâ”€â”€ helpers/                      # Helper functions
â”‚   â”‚   â”œâ”€â”€ interceptors/                 # Response interceptors
â”‚   â”‚   â””â”€â”€ interfaces/                   # Common interfaces
â”‚   â”‚
â”‚   â”œâ”€â”€ configs/                          # Configuration modules
â”‚   â”‚   â”œâ”€â”€ auth.config.ts                # JWT configuration
â”‚   â”‚   â”œâ”€â”€ aws.config.ts                 # S3 configuration
â”‚   â”‚   â”œâ”€â”€ kafka.config.ts               # Kafka configuration
â”‚   â”‚   â”œâ”€â”€ opensearch.config.ts          # OpenSearch configuration
â”‚   â”‚   â”œâ”€â”€ postgres.config.ts            # PostgreSQL configuration
â”‚   â”‚   â”œâ”€â”€ redis.config.ts               # Redis configuration
â”‚   â”‚   â”œâ”€â”€ server.config.ts              # Server configuration
â”‚   â”‚   â””â”€â”€ swagger.config.ts             # Swagger/OpenAPI configuration
â”‚   â”‚
â”‚   â”œâ”€â”€ database/                         # Database modules
â”‚   â”‚   â”œâ”€â”€ opensearch/                   # OpenSearch integration
â”‚   â”‚   â”‚   â”œâ”€â”€ opensearch.module.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ opensearch.service.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ builders/                 # Query builders
â”‚   â”‚   â”‚   â””â”€â”€ components/               # Query components
â”‚   â”‚   â”œâ”€â”€ postgres/                     # PostgreSQL integration
â”‚   â”‚   â”‚   â”œâ”€â”€ postgres-database.module.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ abstract.entity.ts        # Base entity class
â”‚   â”‚   â”‚   â”œâ”€â”€ entities/                 # TypeORM entities
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ outbox-event.entity.ts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ processed-message.entity.ts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ video-summary.entity.ts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ video-transcript.entity.ts
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ video-variant.entity.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ interfaces/               # Base entity interfaces
â”‚   â”‚   â”‚   â””â”€â”€ repository/               # Generic CRUD repository
â”‚   â”‚   â””â”€â”€ redis/                        # Redis integration
â”‚   â”‚       â”œâ”€â”€ redis-cache.module.ts
â”‚   â”‚       â”œâ”€â”€ redis.service.ts
â”‚   â”‚       â””â”€â”€ redis.factory.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ modules/                          # Feature modules
â”‚   â”‚   â”œâ”€â”€ auth/                       # Authentication module
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.module.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.controller.ts       # Signup, Login, Logout
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.service.ts          # Auth business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ strategy/                # Passport strategies
â”‚   â”‚   â”‚   â””â”€â”€ dtos/                    # Auth DTOs
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ health/                      # Health check module
â”‚   â”‚   â”‚   â”œâ”€â”€ health.module.ts
â”‚   â”‚   â”‚   â””â”€â”€ health.controller.ts     # Health endpoints
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ user/                        # User management module
â”‚   â”‚   â”‚   â”œâ”€â”€ user.module.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ user.controller.ts   # User CRUD operations
â”‚   â”‚   â”‚   â”œâ”€â”€ entities/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ user.entity.ts       # User entity
â”‚   â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ user.service.ts      # User business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ processors/              # BullMQ processors
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ sync-user-emails.processor.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ schedulers/              # Cron schedulers
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ user-email-sync.scheduler.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ bloom-filter-state.service.ts
â”‚   â”‚   â”‚   â””â”€â”€ check-email.dto.ts
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ videos/                      # Videos module (consolidated)
â”‚   â”‚       â”œâ”€â”€ videos.module.ts
â”‚   â”‚       â”œâ”€â”€ controllers/
â”‚   â”‚       â”‚   â”œâ”€â”€ upload.controller.ts      # Video upload endpoints
â”‚   â”‚       â”‚   â”œâ”€â”€ videos.controller.ts     # Video listing/search
â”‚   â”‚       â”‚   â””â”€â”€ watch.controller.ts       # Video playback endpoints
â”‚   â”‚       â”œâ”€â”€ entities/
â”‚   â”‚       â”‚   â”œâ”€â”€ video.entity.ts          # Video entity
â”‚   â”‚       â”‚   â””â”€â”€ upload-metadata.entity.ts
â”‚   â”‚       â”œâ”€â”€ dtos/
â”‚   â”‚       â”‚   â””â”€â”€ upload.dto.ts
â”‚   â”‚       â”œâ”€â”€ services/
â”‚   â”‚       â”‚   â”œâ”€â”€ upload/                  # Upload services
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ upload.service.ts
â”‚   â”‚       â”‚   â”‚   â””â”€â”€ upload-kafka-producer.service.ts
â”‚   â”‚       â”‚   â”œâ”€â”€ watch/                   # Watch services
â”‚   â”‚       â”‚   â”‚   â””â”€â”€ watch.service.ts
â”‚   â”‚       â”‚   â”œâ”€â”€ video-processor/         # Video processing services
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ video-processor.service.ts
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ video-processor-kafka-consumer.service.ts
â”‚   â”‚       â”‚   â”‚   â””â”€â”€ video-transcription.service.ts
â”‚   â”‚       â”‚   â”œâ”€â”€ search/                  # Search services
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ video-search.service.ts
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ video-search-index.service.ts
â”‚   â”‚       â”‚   â”‚   â””â”€â”€ search-kafka-consumer.service.ts
â”‚   â”‚       â”‚   â”œâ”€â”€ shared/                  # Shared services
â”‚   â”‚       â”‚   â”‚   â””â”€â”€ outbox.service.ts
â”‚   â”‚       â”‚   â””â”€â”€ video-info.service.ts
â”‚   â”‚       â”œâ”€â”€ processors/                  # BullMQ job processors
â”‚   â”‚       â”‚   â”œâ”€â”€ video-transcode.processor.ts
â”‚   â”‚       â”‚   â”œâ”€â”€ video-transcribe.processor.ts
â”‚   â”‚       â”‚   â”œâ”€â”€ video-index.processor.ts
â”‚   â”‚       â”‚   â””â”€â”€ outbox-publisher.processor.ts
â”‚   â”‚       â”œâ”€â”€ schedulers/                  # Cron schedulers
â”‚   â”‚       â”‚   â””â”€â”€ outbox-publisher.scheduler.ts
â”‚   â”‚       â”œâ”€â”€ constants/
â”‚   â”‚       â”‚   â”œâ”€â”€ video-processor.constants.ts
â”‚   â”‚       â”‚   â””â”€â”€ search.constants.ts
â”‚   â”‚       â”œâ”€â”€ schemas/
â”‚   â”‚       â”‚   â””â”€â”€ video-search-schema.ts
â”‚   â”‚       â””â”€â”€ interfaces/
â”‚   â”‚           â””â”€â”€ video-search-document.interface.ts
â”‚   â”‚
â”‚   â””â”€â”€ providers/                         # Third-party providers
â”‚       â”œâ”€â”€ bullmq/                        # BullMQ queue management
â”‚       â”‚   â”œâ”€â”€ bullmq.module.ts
â”‚       â”‚   â”œâ”€â”€ bullmq.service.ts
â”‚       â”‚   â””â”€â”€ factory/
â”‚       â”‚       â””â”€â”€ bullmq.factory.ts
â”‚       â”œâ”€â”€ ffmpeg/                        # FFmpeg wrapper
â”‚       â”‚   â”œâ”€â”€ ffmpeg.module.ts
â”‚       â”‚   â””â”€â”€ ffmpeg.service.ts
â”‚       â”œâ”€â”€ kafka/                         # Kafka producer/consumer
â”‚       â”‚   â””â”€â”€ kafka.module.ts
â”‚       â””â”€â”€ s3/                            # AWS S3 client
â”‚           â”œâ”€â”€ s3.module.ts
â”‚           â””â”€â”€ s3.service.ts
â”‚
â””â”€â”€ package.json                           # Dependencies and scripts
```

### Key Features

#### 1. **Video Upload & Processing Pipeline**

Flow:
```
Upload â†’ Transcode â†’ Transcribe â†’ (Kafka) â†’ Summarize (Python) â†’ Index â†’ Ready
```

**Stages:**
1. **Upload** (`UploadController` â†’ `UploadService`)
   - Receives video file via multipart upload
   - Generates presigned S3 URLs for upload
   - Creates video record with status `PENDING`
   - Publishes `video.uploaded` event to Kafka

2. **Transcoding** (`VideoProcessorService` â†’ `VideoTranscodeProcessor`)
   - Consumes `video.uploaded` event
   - Downloads video from S3
   - Transcodes using FFmpeg to multiple variants (720p, 1080p)
   - Uploads variants to S3
   - Updates status to `TRANSCRIBING`
   - Publishes `video.transcoded` event

3. **Transcription** (`VideoTranscriptionService` â†’ `VideoTranscribeProcessor`)
   - Consumes `video.transcoded` event
   - Downloads video from S3
   - Extracts audio and transcribes using FFmpeg/whisper
   - Saves transcript to `video_transcripts` table
   - Uploads transcript JSON to S3
   - Updates status to `SUMMARIZING`
   - Publishes `video.transcribed` event to Kafka (consumed by Python)

4. **Summarization** (Python Backend - see below)

5. **Indexing** (`VideoSearchIndexService` â†’ `VideoIndexProcessor`)
   - Consumes `video.summarized` event from Kafka
   - Downloads summary and metadata
   - Indexes video in OpenSearch for search
   - Updates status to `READY`
   - Sets `processed_at` timestamp

#### 2. **Video Search**

- **OpenSearch Integration:** Full-text search across video titles, descriptions, transcripts, summaries
- **Query Builder:** Component-based query construction (match, multi-match, filters, range, geo)
- **Pagination:** Cursor-based pagination for large result sets
- **Endpoints:** `GET /api/v1/videos/search` with query parameters

#### 3. **Authentication & Authorization**

- **JWT-based authentication** with Passport.js
- **Endpoints:**
  - `POST /api/v1/auth/signup` - User registration
  - `POST /api/v1/auth/login` - User login
  - `POST /api/v1/auth/logout` - Token blacklisting
- **Token blacklisting:** Redis cache for revoked tokens
- **Guards:** `JwtAuthGuard` for protected routes
- **Public decorator:** `@Public()` for public endpoints

#### 4. **User Management**

- **CRUD operations** for user profiles
- **Email checking:** Bloom filter for fast email existence checks
- **Email synchronization:** Scheduled job to sync user emails to Bloom filter
- **Endpoints:**
  - `GET /api/v1/users/me` - Get current user
  - `POST /api/v1/users/check-email` - Check if email exists

#### 5. **Shared Outbox Pattern**

- **Reliable event publishing:** Both NestJS and Python write to `outbox_events` table
- **Centralized publishing:** NestJS scheduler publishes all events (from both services)
- **Benefits:**
  - Atomic transactions (database + outbox in same transaction)
  - Retry mechanism for failed publishes
  - Idempotency via event IDs

### Database Schema

**Tables:**
- `users` - User accounts
- `videos` - Video metadata and status
- `video_transcripts` - Transcription data
- `video_summaries` - AI-generated summaries
- `video_variants` - Multiple quality variants
- `outbox_events` - Event publishing queue
- `processed_messages` - Idempotency tracking
- `upload_metadata` - Upload tracking

**Video Status Enum:**
```typescript
enum VideoProcessingStatus {
  UPLOADING = 'uploading',
  PENDING = 'pending',
  TRANSCODING = 'transcoding',
  TRANSCRIBING = 'transcribing',
  SUMMARIZING = 'summarizing',
  INDEXING = 'indexing',
  READY = 'ready',
  FAILED = 'failed',
}
```

### Kafka Events

**Topics:**
1. `video.uploaded` - Published after video upload
2. `video.transcoded` - Published after video transcoding
3. `video.transcribed` - Published after transcription (consumed by Python)
4. `video.summarized` - Published after summarization (from Python)

### BullMQ Queues

1. **VIDEO_TRANSCODE_QUEUE** - Video transcoding jobs
2. **VIDEO_TRANSCRIBE_QUEUE** - Video transcription jobs
3. **VIDEO_SEARCH_INDEX_QUEUE** - Search indexing jobs
4. **OUTBOX_PUBLISHER_QUEUE** - Event publishing jobs
5. **SYNC_USER_EMAILS_QUEUE** - User email sync jobs

### API Endpoints

**Health:**
- `GET /api/v1/health` - Health check
- `GET /api/v1/health/live` - Liveness probe
- `GET /api/v1/health/ready` - Readiness probe

**Authentication:**
- `POST /api/v1/auth/signup` - Register user
- `POST /api/v1/auth/login` - Login user
- `POST /api/v1/auth/logout` - Logout user

**Users:**
- `GET /api/v1/users/me` - Get current user
- `POST /api/v1/users/check-email` - Check email existence

**Videos:**
- `POST /api/v1/videos/upload` - Upload video
- `GET /api/v1/videos/list` - List videos (paginated)
- `GET /api/v1/videos/search` - Search videos
- `GET /api/v1/videos/:id` - Get video details
- `GET /api/v1/videos/:id/watch` - Get video watch URL
- `GET /api/v1/videos/:id/transcript` - Get video transcript

---

## ğŸ Python Backend (`python-backend`)

### Technology Stack

- **Framework:** FastAPI 0.109.x
- **Database:** PostgreSQL with SQLAlchemy
- **Message Queue:** Kafka (kafka-python, confluent-kafka)
- **Task Queue:** Celery with Redis broker
- **AI/ML:** OpenAI API (GPT-3.5-turbo)
- **Object Storage:** AWS S3 (boto3)
- **Configuration:** Pydantic Settings

### Project Structure

```
python-backend/
â”œâ”€â”€ main.py                      # FastAPI application entry point
â”œâ”€â”€ config.py                    # Configuration (Pydantic Settings)
â”œâ”€â”€ celery_app.py                # Celery application
â”œâ”€â”€ kafka_worker.py              # Kafka consumer worker
â”œâ”€â”€ run.py                       # FastAPI server runner
â”œâ”€â”€ run_all.py                   # Run all services together
â”‚
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ base.py                  # Database base and session factory
â”‚   â”œâ”€â”€ models.py                # SQLAlchemy models
â”‚   â””â”€â”€ repository.py            # Generic CRUD repository
â”‚
â”œâ”€â”€ kafka_client/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ consumer.py              # Kafka consumer service
â”‚   â”œâ”€â”€ producer.py              # Kafka producer service (unused - uses outbox)
â”‚   â””â”€â”€ topic_manager.py        # Topic creation utilities
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ video_summary_service.py # Video summarization logic
â”‚   â””â”€â”€ outbox_service.py        # Outbox event management
â”‚
â”œâ”€â”€ tasks/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ video_summary.py         # Celery task for summarization
â”‚   â””â”€â”€ outbox_publisher.py      # Outbox publishing task (unused - NestJS handles)
â”‚
â”œâ”€â”€ routers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ health.py                # Health check endpoints
â”‚
â”œâ”€â”€ schedulers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ outbox_publisher.py      # Outbox scheduler (unused - NestJS handles)
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ create_kafka_topics.py   # Kafka topic creation script
â”‚
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ Makefile                      # Development commands
â”œâ”€â”€ README.md                     # Documentation
â”œâ”€â”€ ARCHITECTURE.md               # Architecture documentation
â”œâ”€â”€ FLOW_VERIFICATION.md         # Flow verification
â””â”€â”€ REPOSITORY_SCAN.md            # Repository scan
```

### Key Features

#### 1. **Video Summarization Pipeline**

**Flow:**
```
Kafka Event (video.transcribed)
  â†’ Celery Task Queue
  â†’ Download Transcript from S3
  â†’ Chunk Transcript
  â†’ Map: Summarize Each Chunk (OpenAI)
  â†’ Reduce: Combine Summaries
  â†’ Upload Summary to S3
  â†’ Save to Database
  â†’ Write to Outbox
  â†’ (NestJS publishes to Kafka)
```

**Process:**
1. **Consume Event:** Kafka consumer receives `video.transcribed` event
2. **Queue Task:** Celery task `summarize_video_task` queued
3. **Download Transcript:** Fetch transcript JSON from S3 using `transcriptFileKey`
4. **Chunk Transcript:** Split into 8000-token chunks (preserves metadata)
5. **Map Phase:** Call OpenAI API for each chunk in batches (5 chunks/batch)
   - Uses GPT-3.5-turbo
   - Custom prompts for chunk summarization
6. **Reduce Phase:** Recursively combine chunk summaries
   - If >10 chunks: reduce in batches of 5
   - Final reduction creates 4-6 sentence summary
7. **Upload Summary:** Upload both JSON and text versions to S3
8. **Save to Database:** Write to `video_summaries` table
9. **Update Video Status:** Update `videos.status` to `"indexing"`
10. **Write to Outbox:** Add `video.summarized` event to shared outbox table
    - Transaction ensures atomicity
    - Marked with `service="python-backend"`

#### 2. **Map-Reduce Implementation**

**Map Phase:**
- Chunks transcript by token count (~8000 tokens/chunk)
- Processes chunks in batches (5 at a time) to handle rate limits
- Each chunk gets summarized with OpenAI API
- Returns list of chunk summaries

**Reduce Phase:**
- Recursively combines summaries
- For large sets: reduces in batches of 5
- Final reduction uses specialized prompt for coherent 4-6 sentence summary
- Includes quality scoring

#### 3. **OpenAI Integration**

- **Model:** GPT-3.5-turbo
- **Rate Limiting:** Handled via batching
- **Error Handling:** Retries and error recovery
- **Token Management:** Chunking prevents token limits
- **Quality Scoring:** Calculates summary quality metrics

#### 4. **Outbox Pattern**

- **Shared Table:** Both services write to `outbox_events`
- **Python writes:** After summarization, writes event to outbox
- **NestJS publishes:** Scheduler picks up all events and publishes to Kafka
- **Service Tagging:** Events marked with `service="python-backend"`

### Database Models

**SQLAlchemy Models:**
- `Videos` - Video metadata (matches NestJS entity)
- `VideoTranscript` - Transcription data
- `VideoSummary` - AI-generated summaries
- `OutboxEvent` - Event publishing queue (UUID primary key)

**Video Status:** Uses string literals matching NestJS enum values:
- `"pending"`, `"uploading"`, `"transcoding"`, `"transcribing"`, `"summarizing"`, `"indexing"`, `"ready"`, `"failed"`

### Kafka Integration

**Consumer:**
- Topic: `video.transcribed`
- Handler: `handle_video_transcribed()`
- Queues: Celery task `summarize_video_task`

**Producer:**
- **Note:** Python does NOT publish directly to Kafka
- Uses shared outbox table (published by NestJS scheduler)

### Celery Tasks

1. **summarize_video_task** - Main summarization task
   - Processes video summary
   - Updates database
   - Writes to outbox

2. **publish_outbox_event_task** - Outbox publishing (unused, NestJS handles)

### API Endpoints

**Health:**
- `GET /` - Root endpoint
- `GET /api/v1` - API info
- `GET /api/v1/health` - Health check
- `GET /api/v1/health/live` - Liveness probe
- `GET /api/v1/health/ready` - Readiness probe

### Running Services

**Development:**
```bash
# Run all services together
python run_all.py

# Or separately:
python run.py              # FastAPI server
celery -A celery_app worker --loglevel=info  # Celery worker
python kafka_worker.py     # Kafka consumer
```

---

## ğŸ”„ Event Flow Architecture

### Complete Video Processing Flow

```
1. Upload Video (NestJS)
   â””â”€> POST /api/v1/videos/upload
       â””â”€> UploadService
           â””â”€> Create video record (status: PENDING)
           â””â”€> Publish: video.uploaded (Kafka)

2. Transcode Video (NestJS)
   â””â”€> Consume: video.uploaded
       â””â”€> VideoProcessorService
           â””â”€> Queue: VIDEO_TRANSCODE_QUEUE
               â””â”€> VideoTranscodeProcessor
                   â””â”€> Download video from S3
                   â””â”€> Transcode with FFmpeg
                   â””â”€> Upload variants to S3
                   â””â”€> Update status: TRANSCODING â†’ TRANSCRIBING
                   â””â”€> Publish: video.transcoded (Kafka)

3. Transcribe Video (NestJS)
   â””â”€> Consume: video.transcoded
       â””â”€> VideoTranscriptionService
           â””â”€> Queue: VIDEO_TRANSCRIBE_QUEUE
               â””â”€> VideoTranscribeProcessor
                   â””â”€> Download video from S3
                   â””â”€> Extract audio and transcribe
                   â””â”€> Save transcript to database
                   â””â”€> Upload transcript JSON to S3
                   â””â”€> Update status: TRANSCRIBING â†’ SUMMARIZING
                   â””â”€> Write to outbox: video.transcribed
                       â””â”€> (Outbox publisher publishes to Kafka)

4. Summarize Video (Python)
   â””â”€> Consume: video.transcribed (Kafka)
       â””â”€> kafka_worker.py
           â””â”€> Queue: Celery task summarize_video_task
               â””â”€> VideoSummaryService
                   â””â”€> Download transcript from S3
                   â””â”€> Chunk transcript
                   â””â”€> Map: Summarize chunks with OpenAI
                   â””â”€> Reduce: Combine summaries
                   â””â”€> Upload summary to S3
                   â””â”€> Save to video_summaries table
                   â””â”€> Update status: SUMMARIZING â†’ INDEXING
                   â””â”€> Write to outbox: video.summarized
                       â””â”€> (NestJS outbox publisher publishes to Kafka)

5. Index Video (NestJS)
   â””â”€> Consume: video.summarized (Kafka)
       â””â”€> VideoSearchIndexService
           â””â”€> Queue: VIDEO_SEARCH_INDEX_QUEUE
               â””â”€> VideoIndexProcessor
                   â””â”€> Download summary from S3
                   â””â”€> Index in OpenSearch
                   â””â”€> Update status: INDEXING â†’ READY
                   â””â”€> Set processed_at timestamp
```

### Outbox Pattern Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Service Writes Event to Outbox (Atomic Transaction)       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  1. Save business data (e.g., video_summaries)      â”‚   â”‚
â”‚  â”‚  2. Insert into outbox_events                        â”‚   â”‚
â”‚  â”‚     - topic: "video.summarized"                      â”‚   â”‚
â”‚  â”‚     - payload: {...}                                  â”‚   â”‚
â”‚  â”‚     - service: "python-backend"                       â”‚   â”‚
â”‚  â”‚     - published: false                                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  Both in same database transaction (atomic)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NestJS Outbox Scheduler (runs every 5 seconds)            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  1. Query outbox_events WHERE published = false     â”‚   â”‚
â”‚  â”‚  2. For each event:                                  â”‚   â”‚
â”‚  â”‚     - Queue: OUTBOX_PUBLISHER_QUEUE                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Outbox Publisher Processor (BullMQ)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  1. Publish to Kafka topic                           â”‚   â”‚
â”‚  â”‚  2. Mark as published: published = true             â”‚   â”‚
â”‚  â”‚  3. Set published_at timestamp                       â”‚   â”‚
â”‚  â”‚  4. Increment attempts on failure                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—„ï¸ Database Schema

### Shared Tables (Both Services)

#### `videos`
```sql
- id: INTEGER (PK, auto)
- title: TEXT
- description: TEXT
- user_id: INTEGER
- user_name: TEXT
- key: TEXT (S3 key)
- status: TEXT (enum values: pending, uploading, transcoding, transcribing, summarizing, indexing, ready, failed)
- status_message: TEXT (nullable)
- processed_at: TIMESTAMP (nullable)
- created_at: TIMESTAMP
- updated_at: TIMESTAMP
```

#### `video_transcripts`
```sql
- id: INTEGER (PK, auto)
- video_id: INTEGER (UNIQUE)
- transcript_text: TEXT (nullable)
- transcript_path: TEXT (nullable, S3 key)
- status: TEXT
- duration_seconds: INTEGER (nullable)
- model_info: JSON (nullable)
- created_at: TIMESTAMP
- updated_at: TIMESTAMP
```

#### `video_summaries`
```sql
- id: INTEGER (PK, auto)
- video_id: INTEGER (UNIQUE)
- summary_text: TEXT (nullable)
- summary_path: TEXT (nullable, S3 key)
- model_info: JSON (nullable)
- quality_score: FLOAT (nullable)
- created_at: TIMESTAMP
- updated_at: TIMESTAMP
```

#### `outbox_events`
```sql
- id: UUID (PK)
- topic: TEXT
- payload: JSON
- published: BOOLEAN (default: false)
- attempts: INTEGER (default: 0)
- service: TEXT (nullable, e.g., "python-backend", "nest-be")
- created_at: TIMESTAMP
- published_at: TIMESTAMP (nullable)
```

#### `users`
```sql
- id: INTEGER (PK, auto)
- email: TEXT (UNIQUE)
- name: TEXT
- password_hash: TEXT
- created_at: TIMESTAMP
- updated_at: TIMESTAMP
```

#### `video_variants`
```sql
- id: INTEGER (PK, auto)
- video_id: INTEGER
- quality: TEXT (e.g., "720p", "1080p")
- key: TEXT (S3 key)
- created_at: TIMESTAMP
```

#### `processed_messages`
```sql
- id: INTEGER (PK, auto)
- message_id: TEXT (UNIQUE)
- processed_at: TIMESTAMP
```

---

## ğŸ” Configuration

### Environment Variables

**Shared (both services):**
- `HOST_IP` - Common host IP for all services
- `DB_HOST`, `DB_PORT`, `PG_USER`, `PG_PASSWORD`, `DB_NAME`, `DB_SCHEMA` - PostgreSQL
- `REDIS_HOST`, `REDIS_PORT`, `REDIS_PASSWORD` - Redis
- `KAFKA_BROKERS` - Kafka broker addresses
- `AWS_REGION`, `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_YOUTUBE_BUCKET` - S3
- `USE_LOCALSTACK`, `AWS_S3_ENDPOINT` - MinIO/local S3

**NestJS-specific:**
- `PORT` - API server port (default: 8080)
- `NODE_ENV` - Environment (development/production)
- `JWT_SECRET`, `JWT_EXPIRY` - JWT configuration
- `ELASTICSEARCH_URL`, `ELASTICSEARCH_USERNAME`, `ELASTICSEARCH_PASSWORD` - OpenSearch
- `LOG_LEVEL` - Logging level

**Python-specific:**
- `PORT` - API server port (default: 8081)
- `OPENAI_API_KEY` - OpenAI API key
- `CELERY_BROKER_URL`, `CELERY_RESULT_BACKEND` - Celery configuration
- `LOG_LEVEL` - Logging level

---

## ğŸš€ Deployment & Running

### NestJS Backend

```bash
# Install dependencies
cd nest-backend
npm install

# Development
npm run start:dev

# Production build
npm run build
npm run start:prod

# Environment
cp env.sample .env
# Edit .env with your configuration
```

### Python Backend

```bash
# Install dependencies
cd python-backend
pip install -r requirements.txt

# Development (all services)
python run_all.py

# Production (separate processes)
python run.py              # FastAPI server
celery -A celery_app worker --loglevel=info  # Celery worker
python kafka_worker.py     # Kafka consumer

# Environment
cp env.sample .env
# Edit .env with your configuration
```

---

## ğŸ“Š Key Design Patterns

### 1. **Shared Outbox Pattern**
- **Purpose:** Reliable event publishing
- **Implementation:** Both services write to `outbox_events`, NestJS publishes all
- **Benefits:** Atomic transactions, retry mechanism, idempotency

### 2. **Repository Pattern**
- **NestJS:** Generic CRUD repository (`GenericCrudRepository`)
- **Python:** Generic repository (`GenericRepository`)
- **Benefits:** Consistent data access, testability

### 3. **Job Queue Pattern**
- **NestJS:** BullMQ for async job processing
- **Python:** Celery for async task processing
- **Benefits:** Scalability, retry logic, monitoring

### 4. **Service Layer Pattern**
- Both services use service classes for business logic
- Controllers/consumers call services
- Services orchestrate repository operations

### 5. **Event-Driven Architecture**
- Kafka for inter-service communication
- Decoupled services
- Scalable processing pipeline

---

## ğŸ” Search & Indexing

### OpenSearch Integration

**Index:** `videos`
**Document Fields:**
- `id`, `title`, `description`
- `user_id`, `user_name`
- `transcript_text`, `summary_text`
- `status`, `created_at`
- Metadata fields

**Query Features:**
- Multi-match across title, description, transcript, summary
- Filtering by status, user, date range
- Pagination with cursor-based approach
- Sorting and relevance scoring

---

## âœ… Status Tracking

### Video Status Lifecycle

```
PENDING â†’ UPLOADING â†’ TRANSCODING â†’ TRANSCRIBING â†’ SUMMARIZING â†’ INDEXING â†’ READY
                                                                              â†“
                                                                           FAILED (on error)
```

**Status Updates:**
- `PENDING`: Initial video creation
- `UPLOADING`: File upload in progress
- `TRANSCODING`: Video transcoding
- `TRANSCRIBING`: Audio transcription
- `SUMMARIZING`: AI summarization (Python)
- `INDEXING`: Search index update
- `READY`: Processing complete
- `FAILED`: Error occurred (status_message contains details)

---

## ğŸ“ Notes & Recommendations

### Current State
- âœ… Both backends synchronized
- âœ… Database schemas match
- âœ… Kafka event contracts align
- âœ… Status tracking consistent
- âœ… Outbox pattern working

### Recommendations
1. **Status Enum Consistency:** Consider Python enum class for type safety (optional)
2. **Monitoring:** Add monitoring/metrics (Prometheus, Grafana)
3. **Error Handling:** Enhance error recovery and dead letter queues
4. **Testing:** Add integration tests for event flow
5. **Documentation:** API documentation (Swagger) is available

---

## ğŸ“š Documentation Files

- `SYNC_REPORT.md` - Synchronization verification report
- `python-backend/README.md` - Python backend documentation
- `python-backend/ARCHITECTURE.md` - Architecture details
- `python-backend/FLOW_VERIFICATION.md` - Flow verification
- `python-backend/REPOSITORY_SCAN.md` - Python backend scan

---

**End of Repository Scan Report**

